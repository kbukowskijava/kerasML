{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3d9cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stworzona dwuwarstwowa sieć neuronowa, z wyliczeniem błędu RMSE dla zbioru treningowego/testowego i podsumowanie błędu dla zbioru testowego - tp/tn/fn/fp, recall.\n",
    "# Dane mogą być sztucznie wygenerowane np: waga-wzrost albo wiek-liczba ludności,\n",
    "# tak naprawdę dowolny zbiór danych.\n",
    "# Można pracować na gotowych danych dostępnych w internecie.\n",
    "# Do tego jakieś wykresy. Proszę również o wycenę takiego projektu.\n",
    "\n",
    "##################################################################\n",
    "# DATASETS:\n",
    "# name of the dataset: weather.csv\n",
    "# description: This dataset contains 14 different features such as air temperature, atmospheric pressure, and humidity. These were collected every 10 minutes, beginning in 2003.\n",
    "#             For efficiency, you will use only the data collected between 2009 and 2016.\n",
    "# name of the dataset: books.csv\n",
    "# description: More than 30,000 books in spanish of different narratives with image and ISBN and other features.\n",
    "#             Given in three different formats: CSV, XLSX and JSON.\n",
    "###################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958f689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "import windowGenerator as wg\n",
    "import logging\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ccad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['font.size'] = 8\n",
    "json_file_path = \"config.json\"  # ścieżka do pliku konfiguracyjnego\n",
    "\n",
    "# załadowanie pliku JSON do dict'a config\n",
    "with open(json_file_path) as json_file:\n",
    "    config = json.load(json_file)\n",
    "\n",
    "\n",
    "def read_csv(csvFilePath):\n",
    "    return pd.read_csv(csvFilePath)\n",
    "\n",
    "\n",
    "def show_tpr_graphs(dataFrame):\n",
    "    try:\n",
    "        logging.info(\"Przygotowywanie wykresów...\")\n",
    "        plot_cols = ['T (degC)', 'p (mbar)', 'rh (%)']\n",
    "        plot_features = dataFrame[plot_cols]\n",
    "        plot_features.index = dataFrame['Date Time']\n",
    "        _ = plot_features.plot(subplots=True)\n",
    "        # wyrysowanie wykresu dla ostatnich 288 (48h) przypadków - dane są pobierane co 10 minut\n",
    "        plot_features = dataFrame[plot_cols][:288]\n",
    "        plot_features.index = dataFrame['Date Time'][:288]\n",
    "        _ = plot_features.plot(subplots=True)\n",
    "        plt.show()\n",
    "        logging.info(\"Wykresy wygenerowane poprawnie!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Pojawił się błąd podczas rysowania wykresów danych treningowych. Powód: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac15d65",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1790904462.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [6]\u001b[1;36m\u001b[0m\n\u001b[1;33m    logging.info(\"odczytanie danych do trenowania z pliku CSV\")\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    " # odczytanie danych do trenowania z pliku CSV\n",
    "    logging.info(\"odczytanie danych do trenowania z pliku CSV\")\n",
    "    train_df = read_csv(\"weather.csv\")\n",
    "\n",
    "    # odfiltrowanie najważniejszych kolumn\n",
    "    # filterArray = ['title', 'isbn']\n",
    "    logging.info(\"odfiltrowanie najważniejszych kolumn\")\n",
    "    filterArray = ['Date Time', 'p (mbar)', 'T (degC)', 'rh (%)', 'VPmax (mbar)']\n",
    "    train_df = train_df.filter(items=filterArray)\n",
    "    train_df['Date Time'] = pd.to_datetime(train_df.pop('Date Time'), format='%d.%m.%Y %H:%M:%S')\n",
    "    logging.info(\n",
    "        f\"Załadowano dane z plik CSV.\\n Dataframe head:\\n{train_df.head(config['amountOfHeadRows'])}\\nSprawdzenie poprawności filtrowania...\")\n",
    "\n",
    "    # sprawdzenie poprawności filtrowania:\n",
    "    if train_df.shape[1] == len(filterArray):\n",
    "        logging.info(\"Odfiltrowywanie zakończone sukcesem!\")\n",
    "    else:\n",
    "        raise Exception('Sprawdz, czy nie ma literowek w filtrach <filterArray>')\n",
    "\n",
    "    show_tpr_graphs(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8051d4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
